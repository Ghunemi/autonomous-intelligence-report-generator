# Ollama LLM settings
OLLAMA_MODEL=llama3
OLLAMA_BASE_URL=http://localhost:11434

# Pipeline settings
MAX_SOURCES=10
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=8192
OUTPUT_DIR=output
